{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ab624f0-26cf-4058-9b59-8c60d2291cf6",
   "metadata": {},
   "source": [
    "# DEPENDENCIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31c7b727-d3c7-4bed-ae9c-ec6d474f2d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# Suppress all UserWarnings\n",
    "warnings.simplefilter(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f4ba36-f49e-4119-b821-5744664ac9c8",
   "metadata": {},
   "source": [
    "## Data Preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cb16d0d-1a86-4992-8448-72f46d527410",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(index, main_dir, batch_size, img_height, img_width, train_indices, valid_indices):\n",
    "    \"\"\"\n",
    "    Load subset of data for training/validation.\n",
    "\n",
    "    Args:\n",
    "        index (int): 0 for training data, 1 for validation data.\n",
    "        main_dir (str): Directory containing the image dataset.\n",
    "        batch_size (int): Batch size for data loading.\n",
    "        img_height (int): Height of input images.\n",
    "        img_width (int): Width of input images.\n",
    "        train_indices (list): Indices for training dataset.\n",
    "        valid_indices (list): Indices for validation dataset.\n",
    "\n",
    "    Returns:\n",
    "        tuple: DataLoader object for subset and list of classes.\n",
    "    \"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((img_height, img_width)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    full_dataset = datasets.ImageFolder(root=main_dir, transform=transform)\n",
    "    \n",
    "    subset_indices = train_indices if index == 0 else valid_indices\n",
    "    \n",
    "    subset_dataset = torch.utils.data.Subset(full_dataset, subset_indices)\n",
    "    classes = full_dataset.classes\n",
    "    \n",
    "    return DataLoader(subset_dataset, batch_size=batch_size, shuffle=True, pin_memory=True), classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49b1017-c76d-4db7-8fb9-e091917ed382",
   "metadata": {},
   "source": [
    "## Function using Multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ab10570-c6d5-4ad1-9fbe-60c1fe525639",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loaders(main_dir, batch_size, img_height, img_width):\n",
    "    \"\"\"\n",
    "    Constructs and returns data loaders for training and validation sets using multiprocessing.\n",
    "\n",
    "    Args:\n",
    "        main_dir (str): The main directory containing the image dataset.\n",
    "        batch_size (int): The batch size for data loaders.\n",
    "        img_height (int): The height of the input images.\n",
    "        img_width (int): The width of the input images.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the training data loader and the validation data loader.\n",
    "        \n",
    "    Note:\n",
    "        This function uses multiprocessing for loading data in parallel, which can be more efficient\n",
    "        especially for large datasets. It splits the dataset into training and validation sets,\n",
    "        and then loads them using separate processes. The `num_workers` parameter controls the number\n",
    "        of worker processes for data loading.\n",
    "    \"\"\"\n",
    "    num_workers = 32\n",
    "    print(f\"Number of CPUs: {num_workers}\")\n",
    "\n",
    "    full_dataset = datasets.ImageFolder(root=main_dir)\n",
    "    total_size = len(full_dataset)\n",
    "    indices = list(range(total_size))\n",
    "    np.random.shuffle(indices)\n",
    "    train_size = int(0.9 * total_size)\n",
    "    train_indices, valid_indices = indices[:train_size], indices[train_size:]\n",
    "\n",
    "    with Pool(processes=num_workers) as pool:\n",
    "        train_loader = pool.apply_async(load_data, (0, main_dir, batch_size, img_height, img_width, train_indices, valid_indices))\n",
    "        valid_loader = pool.apply_async(load_data, (1, main_dir, batch_size, img_height, img_width, train_indices, valid_indices))\n",
    "\n",
    "        train_loader, valid_loader = train_loader.get(), valid_loader.get()\n",
    "\n",
    "    return train_loader, valid_loader, full_dataset, train_indices, valid_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db9e762b-2348-47f7-9cc9-e315482b7918",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, valid_loader, criterion, optimizer, device, epochs, full_dataset, train_indices, valid_indices, patience=3):\n",
    "    best_val_acc = 0.0\n",
    "    counter = 0\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    train_accuracies = []\n",
    "    valid_accuracies = []\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(f'Total Samples: {len(full_dataset)}')\n",
    "    print(f'Total Training Samples: {len(train_indices)}, Total Validation Samples: {len(valid_indices)}\\n')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start_time = time.time()\n",
    "\n",
    "        # Training\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for step, (images, labels) in enumerate(train_loader, 1):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_acc = correct / total\n",
    "        train_losses.append(epoch_loss)\n",
    "        train_accuracies.append(epoch_acc)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in valid_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_accuracy = val_correct / val_total\n",
    "        val_loss /= len(valid_loader)\n",
    "        valid_losses.append(val_loss)\n",
    "        valid_accuracies.append(val_accuracy)\n",
    "\n",
    "        # # Early stopping\n",
    "        # if val_accuracy > best_val_acc:\n",
    "        #     best_val_acc = val_accuracy\n",
    "        #     counter = 0\n",
    "        # else:\n",
    "        #     counter += 1\n",
    "        #     if counter >= patience:\n",
    "        #         print(\"Early stopping.\")\n",
    "        #         break\n",
    "\n",
    "        epoch_end_time = time.time()\n",
    "        epoch_time = epoch_end_time - epoch_start_time\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{epochs} - Training Loss: {epoch_loss:.4f} - Training Accuracy: {epoch_acc:.4f} - Validation Loss: {val_loss:.4f} - Validation Accuracy: {val_accuracy:.4f} - Time: {epoch_time:.2f}s\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    print(f\"Total training time: {total_time:.2f}s\")\n",
    "\n",
    "    return train_losses, train_accuracies, valid_losses, valid_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16075d4d-4687-4c93-8724-acc1d25b6384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPUs: 32\n",
      "Total Samples: 12610\n",
      "Total Training Samples: 11349, Total Validation Samples: 1261\n",
      "\n",
      "Epoch 1/20 - Training Loss: 0.5060 - Training Accuracy: 0.7507 - Validation Loss: 0.4801 - Validation Accuracy: 0.7748 - Time: 724.18s\n",
      "Epoch 2/20 - Training Loss: 0.3854 - Training Accuracy: 0.8158 - Validation Loss: 0.4596 - Validation Accuracy: 0.8017 - Time: 685.80s\n",
      "Epoch 3/20 - Training Loss: 0.3383 - Training Accuracy: 0.8410 - Validation Loss: 1.2159 - Validation Accuracy: 0.7914 - Time: 676.71s\n",
      "Epoch 4/20 - Training Loss: 0.3134 - Training Accuracy: 0.8514 - Validation Loss: 0.4229 - Validation Accuracy: 0.8128 - Time: 690.16s\n",
      "Epoch 5/20 - Training Loss: 0.2873 - Training Accuracy: 0.8610 - Validation Loss: 0.4325 - Validation Accuracy: 0.8073 - Time: 677.12s\n",
      "Epoch 6/20 - Training Loss: 0.2723 - Training Accuracy: 0.8708 - Validation Loss: 0.4276 - Validation Accuracy: 0.8033 - Time: 677.47s\n",
      "Epoch 7/20 - Training Loss: 0.2527 - Training Accuracy: 0.8792 - Validation Loss: 0.4475 - Validation Accuracy: 0.8041 - Time: 677.30s\n",
      "Epoch 8/20 - Training Loss: 0.2355 - Training Accuracy: 0.8844 - Validation Loss: 0.4777 - Validation Accuracy: 0.8128 - Time: 676.92s\n",
      "Epoch 9/20 - Training Loss: 0.2215 - Training Accuracy: 0.8937 - Validation Loss: 0.4750 - Validation Accuracy: 0.7978 - Time: 672.45s\n",
      "Epoch 10/20 - Training Loss: 0.2116 - Training Accuracy: 0.8956 - Validation Loss: 0.5596 - Validation Accuracy: 0.8017 - Time: 670.21s\n",
      "Epoch 11/20 - Training Loss: 0.2010 - Training Accuracy: 0.9044 - Validation Loss: 0.4849 - Validation Accuracy: 0.8105 - Time: 679.67s\n",
      "Epoch 12/20 - Training Loss: 0.1898 - Training Accuracy: 0.9081 - Validation Loss: 0.5317 - Validation Accuracy: 0.8010 - Time: 669.41s\n",
      "Epoch 14/20 - Training Loss: 0.1736 - Training Accuracy: 0.9193 - Validation Loss: 0.5557 - Validation Accuracy: 0.8128 - Time: 672.58s\n",
      "Epoch 15/20 - Training Loss: 0.1595 - Training Accuracy: 0.9234 - Validation Loss: 0.5457 - Validation Accuracy: 0.8136 - Time: 663.54s\n",
      "Epoch 16/20 - Training Loss: 0.1512 - Training Accuracy: 0.9260 - Validation Loss: 0.5828 - Validation Accuracy: 0.8081 - Time: 669.89s\n",
      "Epoch 18/20 - Training Loss: 0.1448 - Training Accuracy: 0.9310 - Validation Loss: 0.6687 - Validation Accuracy: 0.8065 - Time: 666.23s\n",
      "Epoch 19/20 - Training Loss: 0.1472 - Training Accuracy: 0.9300 - Validation Loss: 0.5605 - Validation Accuracy: 0.8065 - Time: 672.84s\n",
      "Epoch 20/20 - Training Loss: 0.1381 - Training Accuracy: 0.9358 - Validation Loss: 0.6073 - Validation Accuracy: 0.8073 - Time: 669.04s\n",
      "Total training time: 13530.39s\n"
     ]
    }
   ],
   "source": [
    "# Define paths to your dataset\n",
    "main_dir = \"/home/gurram.ri/Project/CASIA\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 32\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "\n",
    "train_loader, valid_loader, full_dataset, train_indices, valid_indices = get_data_loaders(main_dir, batch_size, img_height, img_width)\n",
    "\n",
    "# Access DataLoader objects from the tuple\n",
    "train_loader, valid_loader = train_loader[0], valid_loader[0]\n",
    "\n",
    "# Define the EfficientNetB3-based model with custom classifier\n",
    "class EfficientNetB3(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(EfficientNetB3, self).__init__()\n",
    "        self.base_model = models.efficientnet_b3(pretrained=True)\n",
    "        self.base_model.classifier = nn.Identity() #removes final fully connected layer\n",
    "        num_features = self.base_model(torch.zeros(1, 3, 224, 224)).shape[1]\n",
    "        self.classifier = nn.Linear(num_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Define the model\n",
    "classes = train_loader.dataset.dataset.classes\n",
    "num_classes = len(classes)\n",
    "model = EfficientNetB3(num_classes=num_classes).to(device)\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = optim.Adamax(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train the model\n",
    "train_losses, train_accuracies, valid_losses, valid_accuracies = train_model(model, train_loader, valid_loader, criterion, optimizer, device, epochs=20, full_dataset=full_dataset, train_indices=train_indices, valid_indices=valid_indices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
